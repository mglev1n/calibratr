% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/brier.R
\name{brier}
\alias{brier}
\alias{brier.data.frame}
\alias{brier_vec}
\alias{sbrier_vec}
\alias{sbrier}
\alias{sbrier.data.frame}
\title{Brier score}
\usage{
brier(data, ...)

\method{brier}{data.frame}(
  data,
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  event_level = "first",
  ...
)

brier_vec(
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  event_level = "first",
  ...
)

sbrier_vec(
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  event_level = "first",
  ...
)

sbrier(data, ...)

\method{sbrier}{data.frame}(
  data,
  truth,
  estimate,
  estimator = NULL,
  na_rm = TRUE,
  event_level = "first",
  ...
)
}
\arguments{
\item{data}{A data.frame containing the columns specified by truth and ....}

\item{...}{not currently used}

\item{truth}{A data.frame containing the columns specified by \code{truth} and \code{estimate}}

\item{estimate}{If truth is binary, a numeric vector of class probabilities corresponding to the "relevant" class.}

\item{estimator}{"binary" is only relevant for the two class case}

\item{na_rm}{A logical value indicating whether NA values should be stripped before the computation proceeds.}

\item{event_level}{A single string. Either "first" or "second" to specify which level of truth to consider as the "event". This argument is only applicable when estimator = "binary".}
}
\description{
\code{brier()} is a metric that computes the Brier score, given by: \deqn{ BS = \frac{1}{N} \sum (y - \hat y)^2}
\code{sbrier()} is a metric that computes the scaled Brier score (Brier Skill Score), given by: \deqn{ BS_{scaled} = 1 - \frac{BS}{BS_{max}}} where
\deqn{BS_{max} = \frac{1}{N} \sum (y - \bar y)^2}
}
\details{
Brier scores within the interval between 0 and 1, with scores closer to 0 indicating better model performance. The scaled Brier score (also known as Brier Skill Score) ranges from \code{-Inf} to 1, with scores closer to 1 indicating better model performance. Scores less than 0 represent models performing worse than a reference, and scores equal to 1 represent models equivalent to predicting the overall frequency of the class being predicted within the dataset being scored.
}
\references{
Brier, Glenn (1950). "VERIFICATION OF FORECASTS EXPRESSED IN TERMS OF PROBABILITY." \emph{Monthly Weather Review}. Vol 78, Iss 1, pp 1-3
}
\author{
Michael Levin
}
\concept{class probability metrics}
